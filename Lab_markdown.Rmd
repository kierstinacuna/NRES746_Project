---
title: "Ordination Lab"
author: "Kierstin Acuna & Martin Genova"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## RDA Review

The basic steps of redundancy analysis (RDA) are:

1.  Regress each response variable in y over the predictor variables in x\
    ![](images/Lab_1.png)
2.  Perform a PCA on the model predictions\
    ![](images/Lab_2.png)

Of course, the actual RDA function from the vegan package is a bit more sophisticated than this. It involves QR decomposition and some complex matrix algebra. But, today we will focus on using RDA, rather than getting into the weeds with matrix math.

### Doubs Fish Data

For this example, we will be using the Doubs fish data (Verneaux, 1973). It contains 3 datasets. Doubs.fish is a dataset containing counts of 27 species observed across 30 sites in the Doubs river in France. Doubs.env and Doubs.geo are datasets containing attributes on each site, such as longitude and latitude, slope, pH, and dissolved oxygen concentration.

```{r Doubs fish data, message=F}
# Load libraries ----
library(codep)
library(vegan)

# Load Doubs fish Data ----
data(Doubs)
species <- as.data.frame(Doubs.fish[-8,])
vars <- as.data.frame(cbind(Doubs.env[-8,],Doubs.geo[-8,]))
```

Let's take a closer look at the data, starting with the distribution of abundance values we find.

```{r Exploring the data}
## Explore the data ----
# Count the number of species frequencies in each abundance class
ab <- table(unlist(species))
# Plot distribution of species frequencies
barplot(ab, xlab = "Abundance class", ylab = "Frequency", col = grey(5:0/5))
```

That's a lot of zeros!

We can also look at the spread of our predictor variables. The help page for the Doubs data gives explanations of what the variables mean.

```{r Exploring the data 2}
# Look at the spread of the predictor variables
# ?Doubs
summary(vars)
```

![](images/Lab_3.png)

The predictor variables are all in different units, and are on very different scales!

## Exercise 1

Before we can perform an RDA, we need to center and scale the predictor variables, as well as account for the double-zero problem. In the previous lecture, we talked about how we can use different distance metrics, such as the Bray-Curtis dissimilarity to account for the double-zero problem. Since we are using the canned RDA function, we don't have the option to use the Bray-Curtis dissimilarity. The RDA function uses the euclidean distance metric. Therefore, we need to fix the double-zero problem before we feed the data into the RDA function.

We can use the hellinger-transformation to account for the double-zero problem. The hellinger transformation takes raw abundance values, and transforms them into the square root of the relative abundance. The formula for the hellinger transformation is:\
![](images/Lab_4.png)

where j represents species and i represents sites (yij represents species j in site i). yi. represents the summed abundance of all species in site i.

Write a function called RDA_prep() that uses the hellinger transformation and the scale function to prepare the data for RDA. This function should be specified as follows:

**Input:**

-   x = a dataframe containing the predictor variables\
-   y = a dataframe containing the response variables

**Suggested Algorithm:**

1.  Using the hellinger formula and a for loop, hellinger-transform the y dataframe. (Hint: convert y to a matrix first).\
2.  Use the scale function to center and scale the x dataframe

**Return:**

-   out = a list containing x (the centered and scaled x dataframe) and y (the hellinger-transformed y dataframe)

You can use the following code to check your answer:

```{r Exercise 1, results=F}
decostand(species, "hellinger")
```

After you've made your function, use it to prepare the Doubs fish data for RDA!

## Exercise 2

Now that our data is ready, let's practice using RDA for variable selection! In real life when we are creating models for inference, we should always select variables based on ecological reasoning. But since none of us work on fish in the Doubs river, and we're just trying to get some practice using these functions, we're just going to throw all the data we have at this model!

The ordiR2step() function from the vegan package can help us with variable selection. The concept is similar to the MuMIn::dredge() function. Essentially, it takes a null model and a global model, and then adds predictor variables from the global model to the null model stepwise. If a predictor variable increases the adjusted R2 value, it keeps it.

The two main arguments we need to specify for the ordiR2step() function are object and scope. Object is the null model we want to add to, and scope is the fully specified model we want to pull predictor variables from.

For this exercise, use the rda() function to create null and global models. Then, use the ordiR2step function to choose the best predictor variables. In your word document, answer the following questions:

-   What variables did ordiR2step select?\
-   Can you think of a scenario where it would be appropriate to use ordiR2step (or dredge) for variable selection?

## Exercise 3

So far, we've scaled and transferred our data, and used a variable selection tool to narrow down our predictor variables. In this last exercise, we will run an RDA on our selected variables, plot the output, and assess its R-squared value and significance. After completing these tasks, answer the following questions in your word document:

-   What values did you get for the adjusted R-squared and p-values?\
-   Are there any conclusions you can draw from your RDA plot?
